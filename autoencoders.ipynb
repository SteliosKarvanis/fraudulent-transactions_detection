{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os, datetime\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, LeakyReLU\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score, classification_report, roc_curve\n",
    "%load_ext tensorboard\n",
    "import utils\n",
    "import pickle\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#person = 'Davis'\n",
    "person = 'JOURNEY HOUSE TRAVEL INC'\n",
    "cat_vars = ['Merchant Category Code (MCC)']\n",
    "numeric_vars = ['Amount']\n",
    "categories = ['Cardholder Last Name', 'Cardholder First Initial'] + numeric_vars + cat_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transations = utils.get_person_true_transations_df(df, person, categories, cat_vars, numeric_vars)\n",
    "df_transations = transations[0][0]\n",
    "labels = transations[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_transations, labels, test_size=.2, random_state=42)\n",
    "\n",
    "# Normalize the testing and training data using the MinMaxScaler from the scikit learn package\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Make sure to only fit the scaler on the training data\n",
    "x_train = scaler.fit_transform(df_transations)\n",
    "x_test = scaler.transform(x_test)\n",
    "# convert the data to FP32\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "\n",
    "input_dim = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model hyperparameters\n",
    "latent_dim = 10\n",
    "max_epochs = 15\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=learning_rate)\n",
    "activator = tf.keras.layers.LeakyReLU(alpha=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_data = Input(shape=(input_dim,), name='encoder_input')\n",
    "    \n",
    "    dimensions = [200, 100, 50]\n",
    "    dim = input_dim//2\n",
    "    #while dim > 2*latent_dim:\n",
    "    #    dimensions.append(dim)\n",
    "    #    dim = dim//3\n",
    "\n",
    "    encoder = Dense(dimensions[0],activation=activator, name='encoder_1')(input_data)\n",
    "    encoder = Dropout(.1)(encoder)\n",
    "\n",
    "    lay = 1\n",
    "    for num in dimensions[1:]:\n",
    "        lay += 1\n",
    "        encoder = Dense(num,activation=tf.keras.layers.LeakyReLU(alpha=0.01), name='encoder_'+str(lay))(encoder)\n",
    "        encoder = Dropout(.1)(encoder)\n",
    "        \n",
    "    latent_encoding = Dense(latent_dim, activation='linear', name='latent_encoding')(encoder)\n",
    "\n",
    "    decoder = Dense(dimensions[-1] , activation=tf.keras.layers.LeakyReLU(alpha=0.01), name='decoder_1')(latent_encoding)\n",
    "    decoder = Dropout(.1)(decoder)\n",
    "    dimensions.pop()\n",
    "\n",
    "    lay = 1\n",
    "    for num in dimensions[::-1]:\n",
    "        lay += 1\n",
    "        decoder = Dense(num, activation=tf.keras.layers.LeakyReLU(alpha=0.01), name='decoder_'+ str(lay))(decoder)\n",
    "        decoder = Dropout(.1)(decoder)\n",
    "    \n",
    "    reconstructed_data = Dense(input_dim, activation='linear', name='reconstructed_data')(decoder)\n",
    "    \n",
    "    autoencoder_model = Model(input_data, reconstructed_data)\n",
    "    encoder_model = Model(input_data, latent_encoding)\n",
    "    autoencoder_model.compile(optimizer=opt, loss='mse', metrics=['accuracy'])\n",
    "    encoder_model.compile(optimizer=opt, loss='mse', metrics=['accuracy'])\n",
    "    return autoencoder_model, encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 15:51:45.932051: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-28 15:51:45.933498: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "autoencoder_model, encoder_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 435)]             0         \n",
      "                                                                 \n",
      " encoder_1 (Dense)           (None, 200)               87200     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " encoder_2 (Dense)           (None, 100)               20100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " encoder_3 (Dense)           (None, 50)                5050      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " latent_encoding (Dense)     (None, 10)                510       \n",
      "                                                                 \n",
      " decoder_1 (Dense)           (None, 50)                550       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " decoder_2 (Dense)           (None, 100)               5100      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " decoder_3 (Dense)           (None, 200)               20200     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " reconstructed_data (Dense)  (None, 435)               87435     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 226,145\n",
      "Trainable params: 226,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir,profile_batch=0,update_freq='epoch',histogram_freq=1)\n",
    "batch_size = len(x_train)//10\n",
    "train_history = autoencoder_model.fit(x_train, x_train,\n",
    "        shuffle=True,\n",
    "        epochs=max_epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test)\n",
    "        #callbacks=[tensorboard_callback]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_history.history['loss'])\n",
    "plt.plot(train_history.history['val_loss'])\n",
    "plt.legend(['loss on train data', 'loss on validation data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_recon = autoencoder_model.predict(x_test)\n",
    "reconstruction_scores = np.mean((x_test - x_test_recon)**2, axis=1)\n",
    "plt.xlabel('Reconstruction Score')\n",
    "df_a = pd.DataFrame()\n",
    "df_a['recon_score'] = reconstruction_scores\n",
    "minim, maxim = df_a['recon_score'].min(), df_a['recon_score'].max()\n",
    "df_a['recon_score'].plot.hist(bins=200, range=[minim, maxim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transations_val = utils.get_person_balanced_df(df, person, categories, cat_vars, numeric_vars)\n",
    "df_transations_val = transations_val[0][0]\n",
    "labels_val = transations_val[1][0]\n",
    "scaler = MinMaxScaler()\n",
    "x_test_val = scaler.fit_transform(df_transations_val)\n",
    "\n",
    "x_test_recon_val = autoencoder_model.predict(x_test_val)\n",
    "reconstruction_scores_val = np.mean((x_test_val - x_test_recon_val)**2, axis=1)\n",
    "anomaly_data = pd.DataFrame({'recon_score':reconstruction_scores_val})\n",
    "threshold = anomaly_data['recon_score'].median()\n",
    "print(\"Threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transations_val_2 = utils.get_person_total_df(df, person, categories, cat_vars, numeric_vars)\n",
    "df_transations_val_2 = transations_val_2[0][0]\n",
    "labels_val_2 = transations_val_2[1][0]\n",
    "scaler = MinMaxScaler()\n",
    "x_test_val_2 = scaler.fit_transform(df_transations_val_2)\n",
    "\n",
    "x_test_recon = autoencoder_model.predict(x_test_val_2)\n",
    "reconstruction_scores_2 = np.mean((x_test_val_2 - x_test_recon)**2, axis=1)\n",
    "anomaly_data = pd.DataFrame({'recon_score':reconstruction_scores_2})\n",
    "pred_labels_2 = (reconstruction_scores_2 < threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(pred_labels_2, labels_val_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Reconstruction Score')\n",
    "df_a = pd.DataFrame()\n",
    "df_a['recon_score'] = reconstruction_scores_2\n",
    "minim, maxim = df_a['recon_score'].min(), df_a['recon_score'].max()\n",
    "df_a['recon_score'].plot.hist(bins=200, range=[minim, maxim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Confusion Matrix: ')\n",
    "results = confusion_matrix(labels_val_2, pred_labels_2) \n",
    "utils.plot_confusion_matrix(results, ['Anomaly','Normal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For all persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(name: str):\n",
    "    #Train\n",
    "    transations = utils.get_person_true_transations_df(df, person, categories, cat_vars, numeric_vars)\n",
    "    df_transations = transations[0][0]\n",
    "    labels = transations[1][0]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df_transations, labels, test_size=.2, random_state=42)\n",
    "    scaler = MinMaxScaler()\n",
    "    x_train = scaler.fit_transform(df_transations)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    x_train = x_train.astype(np.float32)\n",
    "    x_test = x_test.astype(np.float32)\n",
    "    autoencoder_model, encoder_model = create_model()\n",
    "    batch_size = len(x_train)//10\n",
    "    train_history = autoencoder_model.fit(x_train, x_train,\n",
    "        shuffle=True,\n",
    "        epochs=max_epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(x_test, x_test)\n",
    "        #callbacks=[tensorboard_callback]\n",
    "        )\n",
    "    #Find Threshold\n",
    "    transations_val = utils.get_person_balanced_df(df, person, categories, cat_vars, numeric_vars)\n",
    "    df_transations_val = transations_val[0][0]\n",
    "    labels_val = transations_val[1][0]\n",
    "    scaler = MinMaxScaler()\n",
    "    x_test_val = scaler.fit_transform(df_transations_val)\n",
    "    x_test_recon_val = autoencoder_model.predict(x_test_val)\n",
    "    reconstruction_scores_val = np.mean((x_test_val - x_test_recon_val)**2, axis=1)\n",
    "    anomaly_data = pd.DataFrame({'recon_score':reconstruction_scores_val})\n",
    "    threshold = anomaly_data['recon_score'].median()\n",
    "    \n",
    "    # Validate\n",
    "    transations_val_2 = utils.get_person_total_df(df, person, categories, cat_vars, numeric_vars)\n",
    "    df_transations_val_2 = transations_val_2[0][0]\n",
    "    labels_val_2 = transations_val_2[1][0]\n",
    "    scaler = MinMaxScaler()\n",
    "    x_test_val_2 = scaler.fit_transform(df_transations_val_2)\n",
    "\n",
    "    x_test_recon = autoencoder_model.predict(x_test_val_2)\n",
    "    reconstruction_scores_2 = np.mean((x_test_val_2 - x_test_recon)**2, axis=1)\n",
    "    anomaly_data = pd.DataFrame({'recon_score':reconstruction_scores_2})\n",
    "    pred_labels_2 = (reconstruction_scores_2 < threshold).astype(int)\n",
    "\n",
    "    return accuracy_score(labels_val_2, pred_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "11/11 [==============================] - 1s 42ms/step - loss: 0.0023 - accuracy: 0.2055 - val_loss: 0.0023 - val_accuracy: 0.2374\n",
      "Epoch 2/15\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0022 - accuracy: 0.2402 - val_loss: 0.0021 - val_accuracy: 0.2374\n",
      "Epoch 3/15\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 0.0021 - accuracy: 0.2457 - val_loss: 0.0020 - val_accuracy: 0.2374\n",
      "Epoch 4/15\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0020 - accuracy: 0.2840 - val_loss: 0.0018 - val_accuracy: 0.3151\n",
      "Epoch 5/15\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0018 - accuracy: 0.3425 - val_loss: 0.0017 - val_accuracy: 0.3927\n",
      "Epoch 6/15\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.0017 - accuracy: 0.4037 - val_loss: 0.0016 - val_accuracy: 0.3927\n",
      "Epoch 7/15\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 0.0017 - accuracy: 0.4100 - val_loss: 0.0015 - val_accuracy: 0.4338\n",
      "Epoch 8/15\n",
      "11/11 [==============================] - 0s 36ms/step - loss: 0.0016 - accuracy: 0.4393 - val_loss: 0.0014 - val_accuracy: 0.4840\n",
      "Epoch 9/15\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0015 - accuracy: 0.4804 - val_loss: 0.0014 - val_accuracy: 0.4840\n",
      "Epoch 10/15\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 0.0015 - accuracy: 0.4785 - val_loss: 0.0014 - val_accuracy: 0.4566\n",
      "Epoch 11/15\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 0.0015 - accuracy: 0.4813 - val_loss: 0.0014 - val_accuracy: 0.4566\n",
      "Epoch 12/15\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.0015 - accuracy: 0.4968 - val_loss: 0.0013 - val_accuracy: 0.5023\n",
      "Epoch 13/15\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0014 - accuracy: 0.5105 - val_loss: 0.0013 - val_accuracy: 0.5023\n",
      "Epoch 14/15\n",
      "11/11 [==============================] - 0s 40ms/step - loss: 0.0014 - accuracy: 0.5333 - val_loss: 0.0013 - val_accuracy: 0.5297\n",
      "Epoch 15/15\n",
      "11/11 [==============================] - 0s 37ms/step - loss: 0.0014 - accuracy: 0.5333 - val_loss: 0.0013 - val_accuracy: 0.5479\n",
      "Epoch 1/15\n",
      "11/11 [==============================] - 1s 76ms/step - loss: 0.0022 - accuracy: 0.2718 - val_loss: 0.0020 - val_accuracy: 0.3538\n",
      "Epoch 2/15\n",
      "11/11 [==============================] - 1s 41ms/step - loss: 0.0020 - accuracy: 0.3172 - val_loss: 0.0017 - val_accuracy: 0.3538\n",
      "Epoch 3/15\n",
      "11/11 [==============================] - 0s 44ms/step - loss: 0.0018 - accuracy: 0.3172 - val_loss: 0.0015 - val_accuracy: 0.3538\n",
      "Epoch 4/15\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0016 - accuracy: 0.3428 - val_loss: 0.0014 - val_accuracy: 0.5094\n",
      "Epoch 5/15\n",
      "11/11 [==============================] - 0s 38ms/step - loss: 0.0016 - accuracy: 0.4934 - val_loss: 0.0014 - val_accuracy: 0.6226\n",
      "Epoch 6/15\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.0015 - accuracy: 0.5379 - val_loss: 0.0013 - val_accuracy: 0.6226\n",
      "Epoch 7/15\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0014 - accuracy: 0.5767 - val_loss: 0.0012 - val_accuracy: 0.6745\n",
      "Epoch 8/15\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0013 - accuracy: 0.6061 - val_loss: 0.0010 - val_accuracy: 0.6226\n",
      "Epoch 9/15\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 0.0012 - accuracy: 0.6127 - val_loss: 8.9703e-04 - val_accuracy: 0.6745\n",
      "Epoch 10/15\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0011 - accuracy: 0.6373 - val_loss: 8.6491e-04 - val_accuracy: 0.6745\n",
      "Epoch 11/15\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0011 - accuracy: 0.6335 - val_loss: 8.5086e-04 - val_accuracy: 0.6745\n",
      "Epoch 12/15\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0010 - accuracy: 0.6288 - val_loss: 8.4283e-04 - val_accuracy: 0.6745\n",
      "Epoch 13/15\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0010 - accuracy: 0.6458 - val_loss: 8.3340e-04 - val_accuracy: 0.6745\n",
      "Epoch 14/15\n",
      "11/11 [==============================] - 0s 42ms/step - loss: 9.9954e-04 - accuracy: 0.6487 - val_loss: 8.0854e-04 - val_accuracy: 0.6981\n",
      "Epoch 15/15\n",
      "11/11 [==============================] - 0s 41ms/step - loss: 9.8479e-04 - accuracy: 0.6657 - val_loss: 7.9037e-04 - val_accuracy: 0.6981\n",
      "Epoch 1/15\n",
      "10/10 [==============================] - 1s 78ms/step - loss: 0.0022 - accuracy: 0.2904 - val_loss: 0.0019 - val_accuracy: 0.4358\n",
      "Epoch 2/15\n",
      "10/10 [==============================] - 1s 56ms/step - loss: 0.0018 - accuracy: 0.4568 - val_loss: 0.0014 - val_accuracy: 0.5901\n",
      "Epoch 3/15\n",
      "10/10 [==============================] - 0s 47ms/step - loss: 0.0014 - accuracy: 0.5869 - val_loss: 0.0011 - val_accuracy: 0.5901\n",
      "Epoch 4/15\n",
      "10/10 [==============================] - 1s 61ms/step - loss: 0.0012 - accuracy: 0.5906 - val_loss: 9.2857e-04 - val_accuracy: 0.6790\n",
      "Epoch 5/15\n",
      "10/10 [==============================] - 1s 62ms/step - loss: 0.0010 - accuracy: 0.6815 - val_loss: 8.0712e-04 - val_accuracy: 0.7432\n",
      "Epoch 6/15\n",
      "10/10 [==============================] - 0s 32ms/step - loss: 9.1695e-04 - accuracy: 0.7422 - val_loss: 6.4439e-04 - val_accuracy: 0.7852\n",
      "Epoch 7/15\n",
      "10/10 [==============================] - 0s 31ms/step - loss: 8.0795e-04 - accuracy: 0.7642 - val_loss: 5.9794e-04 - val_accuracy: 0.7852\n",
      "Epoch 8/15\n",
      "10/10 [==============================] - 0s 44ms/step - loss: 7.6574e-04 - accuracy: 0.7659 - val_loss: 5.7949e-04 - val_accuracy: 0.7852\n",
      "Epoch 9/15\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 7.3876e-04 - accuracy: 0.7681 - val_loss: 5.7569e-04 - val_accuracy: 0.7852\n",
      "Epoch 10/15\n",
      "10/10 [==============================] - 0s 39ms/step - loss: 7.2033e-04 - accuracy: 0.7704 - val_loss: 5.6502e-04 - val_accuracy: 0.8111\n",
      "Epoch 11/15\n",
      "10/10 [==============================] - 1s 59ms/step - loss: 7.0668e-04 - accuracy: 0.7736 - val_loss: 5.5746e-04 - val_accuracy: 0.7852\n",
      "Epoch 12/15\n",
      "10/10 [==============================] - 1s 48ms/step - loss: 6.9103e-04 - accuracy: 0.7783 - val_loss: 5.5046e-04 - val_accuracy: 0.8111\n",
      "Epoch 13/15\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 6.7760e-04 - accuracy: 0.7849 - val_loss: 5.3777e-04 - val_accuracy: 0.8111\n",
      "Epoch 14/15\n",
      "10/10 [==============================] - 1s 55ms/step - loss: 6.5897e-04 - accuracy: 0.7943 - val_loss: 5.2507e-04 - val_accuracy: 0.8111\n",
      "Epoch 15/15\n",
      "10/10 [==============================] - 1s 67ms/step - loss: 6.4201e-04 - accuracy: 0.7948 - val_loss: 5.0679e-04 - val_accuracy: 0.8111\n",
      "Epoch 1/15\n",
      "11/11 [==============================] - 1s 61ms/step - loss: 0.0023 - accuracy: 0.2113 - val_loss: 0.0021 - val_accuracy: 0.2753\n",
      "Epoch 2/15\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0021 - accuracy: 0.4124 - val_loss: 0.0018 - val_accuracy: 0.4044\n",
      "Epoch 3/15\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0017 - accuracy: 0.4687 - val_loss: 0.0016 - val_accuracy: 0.5148\n",
      "Epoch 4/15\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 0.0015 - accuracy: 0.5229 - val_loss: 0.0013 - val_accuracy: 0.5148\n",
      "Epoch 5/15\n",
      "11/11 [==============================] - 0s 33ms/step - loss: 0.0014 - accuracy: 0.5387 - val_loss: 0.0011 - val_accuracy: 0.5879\n",
      "Epoch 6/15\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0013 - accuracy: 0.5873 - val_loss: 0.0011 - val_accuracy: 0.5879\n",
      "Epoch 7/15\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0012 - accuracy: 0.6303 - val_loss: 0.0011 - val_accuracy: 0.6330\n",
      "Epoch 8/15\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 0.0011 - accuracy: 0.6433 - val_loss: 9.7847e-04 - val_accuracy: 0.6330\n",
      "Epoch 9/15\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 0.0011 - accuracy: 0.6716 - val_loss: 9.1238e-04 - val_accuracy: 0.6750\n",
      "Epoch 10/15\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 0.0010 - accuracy: 0.6878 - val_loss: 8.8475e-04 - val_accuracy: 0.6750\n",
      "Epoch 11/15\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 9.8739e-04 - accuracy: 0.6916 - val_loss: 8.7457e-04 - val_accuracy: 0.6750\n",
      "Epoch 12/15\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 9.7862e-04 - accuracy: 0.6922 - val_loss: 8.8903e-04 - val_accuracy: 0.6750\n",
      "Epoch 13/15\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 9.6223e-04 - accuracy: 0.7031 - val_loss: 8.7389e-04 - val_accuracy: 0.6905\n",
      "Epoch 14/15\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 9.5156e-04 - accuracy: 0.7077 - val_loss: 8.4702e-04 - val_accuracy: 0.6905\n",
      "Epoch 15/15\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 9.2579e-04 - accuracy: 0.7149 - val_loss: 8.3910e-04 - val_accuracy: 0.6905\n",
      "Epoch 1/15\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 0.0022 - accuracy: 0.2002 - val_loss: 0.0020 - val_accuracy: 0.2766\n",
      "Epoch 2/15\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0019 - accuracy: 0.3863 - val_loss: 0.0015 - val_accuracy: 0.5149\n",
      "Epoch 3/15\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0015 - accuracy: 0.5865 - val_loss: 0.0011 - val_accuracy: 0.7468\n",
      "Epoch 4/15\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 0.0012 - accuracy: 0.7117 - val_loss: 8.8336e-04 - val_accuracy: 0.7468\n",
      "Epoch 5/15\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 9.9385e-04 - accuracy: 0.7270 - val_loss: 7.4286e-04 - val_accuracy: 0.7468\n",
      "Epoch 6/15\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 8.6920e-04 - accuracy: 0.7585 - val_loss: 6.8649e-04 - val_accuracy: 0.7468\n",
      "Epoch 7/15\n",
      "11/11 [==============================] - 0s 26ms/step - loss: 8.1199e-04 - accuracy: 0.7964 - val_loss: 6.1721e-04 - val_accuracy: 0.8404\n",
      "Epoch 8/15\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 7.3750e-04 - accuracy: 0.8164 - val_loss: 5.7142e-04 - val_accuracy: 0.8404\n",
      "Epoch 9/15\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 6.8569e-04 - accuracy: 0.8262 - val_loss: 5.5851e-04 - val_accuracy: 0.8404\n",
      "Epoch 10/15\n",
      "11/11 [==============================] - 0s 16ms/step - loss: 6.6486e-04 - accuracy: 0.8339 - val_loss: 5.2310e-04 - val_accuracy: 0.8404\n",
      "Epoch 11/15\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 6.2779e-04 - accuracy: 0.8394 - val_loss: 5.0092e-04 - val_accuracy: 0.8404\n",
      "Epoch 12/15\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 5.9923e-04 - accuracy: 0.8399 - val_loss: 4.5774e-04 - val_accuracy: 0.8404\n",
      "Epoch 13/15\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 5.5358e-04 - accuracy: 0.8416 - val_loss: 4.0764e-04 - val_accuracy: 0.8404\n",
      "Epoch 14/15\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 5.1403e-04 - accuracy: 0.8420 - val_loss: 3.8615e-04 - val_accuracy: 0.8574\n",
      "Epoch 15/15\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 4.9165e-04 - accuracy: 0.8463 - val_loss: 3.6725e-04 - val_accuracy: 0.8617\n",
      "Epoch 1/15\n",
      "11/11 [==============================] - 1s 69ms/step - loss: 0.0023 - accuracy: 0.1487 - val_loss: 0.0021 - val_accuracy: 0.1810\n",
      "Epoch 2/15\n",
      "11/11 [==============================] - 0s 25ms/step - loss: 0.0021 - accuracy: 0.2602 - val_loss: 0.0018 - val_accuracy: 0.4480\n",
      "Epoch 3/15\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 0.0018 - accuracy: 0.4465 - val_loss: 0.0014 - val_accuracy: 0.4480\n",
      "Epoch 4/15\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0015 - accuracy: 0.4474 - val_loss: 0.0013 - val_accuracy: 0.4480\n",
      "Epoch 5/15\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0015 - accuracy: 0.4474 - val_loss: 0.0013 - val_accuracy: 0.4480\n",
      "Epoch 6/15\n",
      "11/11 [==============================] - 0s 32ms/step - loss: 0.0014 - accuracy: 0.4474 - val_loss: 0.0013 - val_accuracy: 0.4480\n",
      "Epoch 7/15\n",
      "11/11 [==============================] - 0s 27ms/step - loss: 0.0014 - accuracy: 0.4474 - val_loss: 0.0013 - val_accuracy: 0.4480\n",
      "Epoch 8/15\n",
      "11/11 [==============================] - 0s 34ms/step - loss: 0.0014 - accuracy: 0.4479 - val_loss: 0.0013 - val_accuracy: 0.4480\n",
      "Epoch 9/15\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 0.0014 - accuracy: 0.4787 - val_loss: 0.0012 - val_accuracy: 0.5158\n",
      "Epoch 10/15\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 0.0013 - accuracy: 0.5027 - val_loss: 0.0012 - val_accuracy: 0.5158\n",
      "Epoch 11/15\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 0.5104 - val_loss: 0.0012 - val_accuracy: 0.5158\n",
      "Epoch 12/15\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 0.0013 - accuracy: 0.5163 - val_loss: 0.0011 - val_accuracy: 0.5158\n",
      "Epoch 13/15\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0012 - accuracy: 0.5231 - val_loss: 0.0011 - val_accuracy: 0.5430\n",
      "Epoch 14/15\n",
      "11/11 [==============================] - 0s 28ms/step - loss: 0.0012 - accuracy: 0.5277 - val_loss: 0.0011 - val_accuracy: 0.5430\n",
      "Epoch 15/15\n",
      "11/11 [==============================] - 0s 31ms/step - loss: 0.0012 - accuracy: 0.5626 - val_loss: 0.0011 - val_accuracy: 0.5814\n",
      "Epoch 1/15\n",
      "11/11 [==============================] - 1s 45ms/step - loss: 0.0015 - accuracy: 0.8070 - val_loss: 5.9564e-04 - val_accuracy: 0.9039\n",
      "Epoch 2/15\n",
      "11/11 [==============================] - 0s 30ms/step - loss: 6.1311e-04 - accuracy: 0.8966 - val_loss: 3.1350e-04 - val_accuracy: 0.9039\n",
      "Epoch 3/15\n",
      "11/11 [==============================] - 0s 29ms/step - loss: 3.9259e-04 - accuracy: 0.9014 - val_loss: 2.0732e-04 - val_accuracy: 0.9640\n",
      "Epoch 4/15\n",
      "11/11 [==============================] - 0s 19ms/step - loss: 2.6558e-04 - accuracy: 0.9597 - val_loss: 1.5031e-04 - val_accuracy: 0.9640\n",
      "Epoch 5/15\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 2.1314e-04 - accuracy: 0.9627 - val_loss: 1.3328e-04 - val_accuracy: 0.9640\n",
      "Epoch 6/15\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 1.8556e-04 - accuracy: 0.9627 - val_loss: 1.1477e-04 - val_accuracy: 0.9640\n",
      "Epoch 7/15\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 1.6701e-04 - accuracy: 0.9627 - val_loss: 9.9924e-05 - val_accuracy: 0.9640\n",
      "Epoch 8/15\n",
      "11/11 [==============================] - 0s 18ms/step - loss: 1.5121e-04 - accuracy: 0.9627 - val_loss: 9.3974e-05 - val_accuracy: 0.9640\n",
      "Epoch 9/15\n",
      "11/11 [==============================] - 0s 22ms/step - loss: 1.3914e-04 - accuracy: 0.9627 - val_loss: 8.6605e-05 - val_accuracy: 0.9640\n",
      "Epoch 10/15\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 1.3243e-04 - accuracy: 0.9627 - val_loss: 8.4026e-05 - val_accuracy: 0.9640\n",
      "Epoch 11/15\n",
      "11/11 [==============================] - 0s 20ms/step - loss: 1.2658e-04 - accuracy: 0.9633 - val_loss: 8.7407e-05 - val_accuracy: 0.9640\n",
      "Epoch 12/15\n",
      "11/11 [==============================] - 0s 23ms/step - loss: 1.2021e-04 - accuracy: 0.9790 - val_loss: 7.9923e-05 - val_accuracy: 0.9850\n",
      "Epoch 13/15\n",
      "11/11 [==============================] - 0s 21ms/step - loss: 1.1186e-04 - accuracy: 0.9892 - val_loss: 6.5518e-05 - val_accuracy: 0.9850\n",
      "Epoch 14/15\n",
      "11/11 [==============================] - 0s 24ms/step - loss: 9.1443e-05 - accuracy: 0.9904 - val_loss: 5.2706e-05 - val_accuracy: 0.9850\n",
      "Epoch 15/15\n",
      "11/11 [==============================] - 0s 17ms/step - loss: 8.0978e-05 - accuracy: 0.9904 - val_loss: 5.0543e-05 - val_accuracy: 0.9850\n",
      "Epoch 1/15\n",
      "10/10 [==============================] - 2s 137ms/step - loss: 0.0020 - accuracy: 0.4094 - val_loss: 0.0014 - val_accuracy: 0.4534\n",
      "Epoch 2/15\n",
      "10/10 [==============================] - 1s 118ms/step - loss: 0.0013 - accuracy: 0.5836 - val_loss: 8.9170e-04 - val_accuracy: 0.7010\n",
      "Epoch 3/15\n",
      "10/10 [==============================] - 1s 110ms/step - loss: 8.6303e-04 - accuracy: 0.7762 - val_loss: 5.3954e-04 - val_accuracy: 0.8798\n",
      "Epoch 4/15\n",
      "10/10 [==============================] - 1s 96ms/step - loss: 5.9209e-04 - accuracy: 0.8935 - val_loss: 3.6235e-04 - val_accuracy: 0.9715\n",
      "Epoch 5/15\n",
      "10/10 [==============================] - 1s 111ms/step - loss: 4.0545e-04 - accuracy: 0.9623 - val_loss: 2.3544e-04 - val_accuracy: 0.9715\n",
      "Epoch 6/15\n",
      "10/10 [==============================] - 1s 109ms/step - loss: 3.0516e-04 - accuracy: 0.9745 - val_loss: 1.7337e-04 - val_accuracy: 0.9715\n",
      "Epoch 7/15\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 2.4981e-04 - accuracy: 0.9748 - val_loss: 1.3811e-04 - val_accuracy: 0.9715\n",
      "Epoch 8/15\n",
      "10/10 [==============================] - 1s 95ms/step - loss: 2.0618e-04 - accuracy: 0.9745 - val_loss: 1.0604e-04 - val_accuracy: 0.9715\n",
      "Epoch 9/15\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 1.7418e-04 - accuracy: 0.9748 - val_loss: 8.5620e-05 - val_accuracy: 0.9715\n",
      "Epoch 10/15\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 1.5371e-04 - accuracy: 0.9747 - val_loss: 8.0285e-05 - val_accuracy: 0.9715\n",
      "Epoch 11/15\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 1.4025e-04 - accuracy: 0.9748 - val_loss: 7.6664e-05 - val_accuracy: 0.9715\n",
      "Epoch 12/15\n",
      "10/10 [==============================] - 1s 91ms/step - loss: 1.3225e-04 - accuracy: 0.9748 - val_loss: 7.4479e-05 - val_accuracy: 0.9715\n",
      "Epoch 13/15\n",
      "10/10 [==============================] - 1s 107ms/step - loss: 1.2427e-04 - accuracy: 0.9748 - val_loss: 7.2044e-05 - val_accuracy: 0.9715\n",
      "Epoch 14/15\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 1.1870e-04 - accuracy: 0.9748 - val_loss: 7.1330e-05 - val_accuracy: 0.9715\n",
      "Epoch 15/15\n",
      "10/10 [==============================] - 1s 127ms/step - loss: 1.1524e-04 - accuracy: 0.9747 - val_loss: 6.8852e-05 - val_accuracy: 0.9715\n",
      "Epoch 1/15\n",
      "11/11 [==============================] - 1s 111ms/step - loss: 0.0019 - accuracy: 0.4672 - val_loss: 0.0013 - val_accuracy: 0.6607\n",
      "Epoch 2/15\n",
      "11/11 [==============================] - 1s 68ms/step - loss: 0.0012 - accuracy: 0.6656 - val_loss: 7.3504e-04 - val_accuracy: 0.7507\n",
      "Epoch 3/15\n",
      "11/11 [==============================] - 1s 68ms/step - loss: 8.0068e-04 - accuracy: 0.7760 - val_loss: 6.0240e-04 - val_accuracy: 0.7507\n",
      "Epoch 4/15\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 6.3801e-04 - accuracy: 0.8238 - val_loss: 4.4546e-04 - val_accuracy: 0.9457\n",
      "Epoch 5/15\n",
      "11/11 [==============================] - 1s 68ms/step - loss: 4.7568e-04 - accuracy: 0.9507 - val_loss: 2.9615e-04 - val_accuracy: 0.9457\n",
      "Epoch 6/15\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 3.7095e-04 - accuracy: 0.9536 - val_loss: 2.2675e-04 - val_accuracy: 0.9457\n",
      "Epoch 7/15\n",
      "11/11 [==============================] - 1s 53ms/step - loss: 2.8897e-04 - accuracy: 0.9538 - val_loss: 1.5552e-04 - val_accuracy: 0.9457\n",
      "Epoch 8/15\n",
      "11/11 [==============================] - 1s 73ms/step - loss: 2.4264e-04 - accuracy: 0.9541 - val_loss: 1.5148e-04 - val_accuracy: 0.9457\n",
      "Epoch 9/15\n",
      "11/11 [==============================] - 1s 66ms/step - loss: 2.3122e-04 - accuracy: 0.9541 - val_loss: 1.4017e-04 - val_accuracy: 0.9457\n",
      "Epoch 10/15\n",
      "11/11 [==============================] - 1s 80ms/step - loss: 2.1244e-04 - accuracy: 0.9541 - val_loss: 1.3628e-04 - val_accuracy: 0.9457\n",
      "Epoch 11/15\n",
      "11/11 [==============================] - 1s 91ms/step - loss: 2.0969e-04 - accuracy: 0.9541 - val_loss: 1.4012e-04 - val_accuracy: 0.9457\n",
      "Epoch 12/15\n",
      "11/11 [==============================] - 1s 84ms/step - loss: 1.8530e-04 - accuracy: 0.9541 - val_loss: 1.2993e-04 - val_accuracy: 0.9457\n",
      "Epoch 13/15\n",
      "11/11 [==============================] - 1s 78ms/step - loss: 1.7791e-04 - accuracy: 0.9543 - val_loss: 1.2816e-04 - val_accuracy: 0.9457\n",
      "Epoch 14/15\n",
      "11/11 [==============================] - 1s 83ms/step - loss: 1.7006e-04 - accuracy: 0.9547 - val_loss: 1.2741e-04 - val_accuracy: 0.9593\n",
      "Epoch 15/15\n",
      "11/11 [==============================] - 1s 100ms/step - loss: 1.6521e-04 - accuracy: 0.9568 - val_loss: 1.2291e-04 - val_accuracy: 0.9593\n",
      "Epoch 1/15\n",
      "11/11 [==============================] - 1s 79ms/step - loss: 0.0019 - accuracy: 0.4462 - val_loss: 0.0013 - val_accuracy: 0.4850\n",
      "Epoch 2/15\n",
      "11/11 [==============================] - 1s 72ms/step - loss: 0.0011 - accuracy: 0.6668 - val_loss: 6.9444e-04 - val_accuracy: 0.8239\n",
      "Epoch 3/15\n",
      "11/11 [==============================] - 1s 71ms/step - loss: 7.3670e-04 - accuracy: 0.8646 - val_loss: 4.6152e-04 - val_accuracy: 0.9358\n",
      "Epoch 4/15\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 5.7677e-04 - accuracy: 0.9286 - val_loss: 3.1999e-04 - val_accuracy: 0.9358\n",
      "Epoch 5/15\n",
      "11/11 [==============================] - 1s 58ms/step - loss: 4.4012e-04 - accuracy: 0.9337 - val_loss: 2.7124e-04 - val_accuracy: 0.9358\n",
      "Epoch 6/15\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 3.6289e-04 - accuracy: 0.9333 - val_loss: 2.1089e-04 - val_accuracy: 0.9358\n",
      "Epoch 7/15\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 3.2127e-04 - accuracy: 0.9333 - val_loss: 1.9284e-04 - val_accuracy: 0.9358\n",
      "Epoch 8/15\n",
      "11/11 [==============================] - 1s 62ms/step - loss: 2.8448e-04 - accuracy: 0.9337 - val_loss: 1.6391e-04 - val_accuracy: 0.9358\n",
      "Epoch 9/15\n",
      "11/11 [==============================] - 0s 41ms/step - loss: 2.5407e-04 - accuracy: 0.9339 - val_loss: 1.4166e-04 - val_accuracy: 0.9358\n",
      "Epoch 10/15\n",
      "11/11 [==============================] - 0s 45ms/step - loss: 2.3512e-04 - accuracy: 0.9344 - val_loss: 1.5297e-04 - val_accuracy: 0.9369\n",
      "Epoch 11/15\n",
      "11/11 [==============================] - 1s 61ms/step - loss: 2.3601e-04 - accuracy: 0.9508 - val_loss: 1.4480e-04 - val_accuracy: 0.9900\n",
      "Epoch 12/15\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 2.1215e-04 - accuracy: 0.9838 - val_loss: 1.0680e-04 - val_accuracy: 0.9900\n",
      "Epoch 13/15\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 1.7677e-04 - accuracy: 0.9889 - val_loss: 9.0252e-05 - val_accuracy: 0.9900\n",
      "Epoch 14/15\n",
      "11/11 [==============================] - 1s 64ms/step - loss: 1.5954e-04 - accuracy: 0.9909 - val_loss: 7.6910e-05 - val_accuracy: 0.9900\n",
      "Epoch 15/15\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 1.4205e-04 - accuracy: 0.9911 - val_loss: 6.4503e-05 - val_accuracy: 0.9900\n"
     ]
    }
   ],
   "source": [
    "persons = list(df['Cardholder Last Name'].unique())\n",
    "quantities = df['Cardholder Last Name'].value_counts()\n",
    "values = []\n",
    "names = []\n",
    "\n",
    "for person in persons:\n",
    "    if quantities[person] > 2000:\n",
    "        accuracy = calc_accuracy(person)\n",
    "        values.append(accuracy) \n",
    "        names.append(quantities[person])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(names, values, \".\")\n",
    "plt.title(\"Accuracy vs Operations Quantities\")\n",
    "plt.xlabel(\"Operations Quantities\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6910408462955862,\n",
       " 0.7785512519525222,\n",
       " 0.8412821640025067,\n",
       " 0.7901728508226314,\n",
       " 0.8688583240578789,\n",
       " 0.7916740714412653,\n",
       " 0.9939647189771122,\n",
       " 0.9505532535800136,\n",
       " 0.9519492484543507,\n",
       " 0.93993948350528]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2315, 2155, 4050, 3322, 2348, 2206, 2141, 9650, 6997, 4511]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ct213')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "598095a934dcb3bb155002048116345118bc48a932469ffb0579a7d18e5f6768"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
